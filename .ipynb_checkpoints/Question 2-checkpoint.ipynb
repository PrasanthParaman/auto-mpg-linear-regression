{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce123293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b534f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12918a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74282690",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dea81b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the base estimator, Random Tree is 0.9473684210526315\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        43\n",
      "           1       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The accuracy from only one estimator\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "print('Accuracy score for the base estimator, Random Tree is', accuracy_score(y_test,y_pred))\n",
    "print('Classification report for the base estimator, Random Tree is \\n', classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663128b6",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd69acb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for 5 estimators is 0.9385964912280702\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        43\n",
      "           1       0.96      0.94      0.95        71\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.93      0.94      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Accuracy Score for 105 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 205 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 305 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 405 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 505 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 605 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 705 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 805 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 905 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 1005 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 1105 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 1205 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 1305 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 1405 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 1505 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 1605 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 1705 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 1805 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for 1905 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 2005 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 2105 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 2205 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 2305 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 2405 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 2505 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 2605 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 2705 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 2805 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 2905 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 3005 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 3105 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 3205 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 3305 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 3405 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 3505 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 3605 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 3705 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for 3805 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 3905 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 4005 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 4105 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 4205 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 4305 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 4405 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 4505 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 4605 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 4705 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 4805 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 4905 estimators is 0.956140350877193\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        43\n",
      "           1       0.96      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#building the bagging classifier\n",
    "for number_estimators in range(5,5000,100):\n",
    "    bag_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=number_estimators,\n",
    "                                bootstrap=True, n_jobs=-1)\n",
    "    bag_clf.fit(X_train, y_train)\n",
    "    y_pred = bag_clf.predict(X_test)\n",
    "    print(f'Accuracy Score for {number_estimators} estimators is', accuracy_score(y_test, y_pred))\n",
    "    print('Classification report for the base estimator, Random Tree is \\n', classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca718be9",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ded22f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for 5 estimators is 0.9649122807017544\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 105 estimators is 0.9649122807017544\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        43\n",
      "           1       0.97      0.97      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Accuracy Score for 205 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 305 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 405 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 505 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 605 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 705 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 805 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 905 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 1005 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 1105 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 1205 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 1305 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 1405 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 1505 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 1605 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 1705 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 1805 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for 1905 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 2005 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 2105 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 2205 estimators is 0.9736842105263158\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score for 2305 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 2405 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 2505 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 2605 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 2705 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 2805 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 2905 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 3005 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 3105 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 3205 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 3305 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 3405 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 3505 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 3605 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 3705 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for 3805 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 3905 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 4005 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 4105 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 4205 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 4305 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 4405 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 4505 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 4605 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 4705 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 4805 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "Accuracy Score for 4905 estimators is 0.9824561403508771\n",
      "Classification report for the base estimator, Random Tree is \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using the adaboost\n",
    "for number_estimators in range(5,5000,100):\n",
    "    ada_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    "                                 n_estimators=number_estimators,\n",
    "                                algorithm='SAMME.R', learning_rate=0.5)\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    y_pred = ada_clf.predict(X_test)\n",
    "    print(f'Accuracy Score for {number_estimators} estimators is', accuracy_score(y_test, y_pred))\n",
    "    print('Classification report for the base estimator, Random Tree is \\n', classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6338a60",
   "metadata": {},
   "source": [
    "<li>I tried Bagging and Adaboost ensemble with the base classifier as DecisionTreeClassifier. </li>\n",
    "<li>The DecisionTreeClassifier on its own gave an accuracy upto 94.7%. </li>\n",
    "<li>The Bagging and Adaboost methods are expected to increase this accuracy as the number of estimators increases. </li>\n",
    "<li>The Bagging method initially gave an accuracy of about 93.8% for 5 estimators(less than that of the base estimator itself). It later performed at 95.6% with 105 estimators and then the accuracy remained constant as the number of estimators increased upto 4905 estimators </li>\n",
    "<li>The Adaboost bagging method was used with the algorithm SAMME.R real boosting algorithm with a learning rate of 0.5. The accuracy increased from 96.4%(for 5 estimators) to 97.3%(for 205 estimators) to 98.2%(for 1905 estimators) and later fluctuated around this level as the number of estimators increased. </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7afc1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
